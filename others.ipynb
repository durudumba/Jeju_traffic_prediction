{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, BaggingRegressor, StackingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from pycaret.regression import *\n",
    "\n",
    "import optuna\n",
    "from optuna import trial\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "train = pd.read_parquet('./train.parquet')\n",
    "test = pd.read_parquet('./test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop Done.\n"
     ]
    }
   ],
   "source": [
    "# Drop\n",
    "\n",
    "train = train.drop(['id', 'road_name', 'vehicle_restricted', 'height_restricted', 'start_node_name', 'end_node_name', 'start_longitude', 'end_latitude'], axis='columns')\n",
    "test = test.drop(['id', 'road_name', 'vehicle_restricted', 'height_restricted', 'start_node_name', 'end_node_name', 'start_longitude', 'end_latitude'], axis='columns')\n",
    "\n",
    "print(\"Drop Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Preprocess Done.\n"
     ]
    }
   ],
   "source": [
    "# Custom Preprocess\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train['maximum_speed_limit'] = train['maximum_speed_limit'].astype('int32')\n",
    "test['maximum_speed_limit'] = test['maximum_speed_limit'].astype('int32')\n",
    "\n",
    "train['weight_restricted'] = train['weight_restricted'].astype('int32')\n",
    "test['weight_restricted'] = test['weight_restricted'].astype('int32')\n",
    "\n",
    "## node turn resticted \n",
    "def combine_turns(df):\n",
    "    turn_restricted = []\n",
    "    for s,e in zip(df['start_turn_restricted'], df['end_turn_restricted']):\n",
    "        if (s=='없음') & (e=='없음'):   turn_restricted.append(0)\n",
    "        elif (s=='없음') & (e=='있음'): turn_restricted.append(1)\n",
    "        elif (s=='있음') & (e=='없음'): turn_restricted.append(2)\n",
    "        else:                          turn_restricted.append(3)\n",
    "\n",
    "    return turn_restricted\n",
    "\n",
    "train['start_turn_restricted'] = combine_turns(train)\n",
    "train['start_turn_restricted'] = le.fit_transform(train['start_turn_restricted'])\n",
    "train.rename(columns={'start_turn_restricted' : 'turn_restricted'}, inplace=True)\n",
    "train = train.drop(['end_turn_restricted'], axis='columns')\n",
    "test['start_turn_restricted'] = combine_turns(test)\n",
    "test['start_turn_restricted'] = le.fit_transform(test['start_turn_restricted'])\n",
    "test.rename(columns={'start_turn_restricted' : 'turn_restricted'}, inplace=True)\n",
    "test = test.drop(['end_turn_restricted'], axis='columns')\n",
    "\n",
    "## day_of_week 평일-휴일\n",
    "day_dict = {'월':0, '화':0, '수':0, '목':0, '금':0,\n",
    "            '토':1, '일':1}\n",
    "train['day_of_week'].replace(day_dict, inplace=True)\n",
    "test['day_of_week'].replace(day_dict, inplace=True)\n",
    "\n",
    "print(\"Custom Preprocess Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor Done.\n"
     ]
    }
   ],
   "source": [
    "# Factor\n",
    "\n",
    "train['road_rating'] = le.fit_transform(train['road_rating'])\n",
    "test['road_rating'] = le.fit_transform(test['road_rating'])\n",
    "\n",
    "train['lane_count'] = le.fit_transform(train['lane_count'])\n",
    "test['lane_count'] = le.fit_transform(test['lane_count'])\n",
    "\n",
    "train['road_type'] = le.fit_transform(train['road_type'])\n",
    "test['road_type'] = le.fit_transform(test['road_type'])\n",
    "\n",
    "# train['day_of_week'] = train['day_of_week'].astype('object')\n",
    "# test['day_of_week'] = test['day_of_week'].astype('object')\n",
    "\n",
    "# train['base_hour'] = train['base_hour'].astype('object')\n",
    "# test['base_hour'] = test['base_hour'].astype('object')\n",
    "\n",
    "# train['lane_count'] = train['lane_count'].astype('object')\n",
    "# test['lane_count'] = test['lane_count'].astype('object')\n",
    "\n",
    "# train['road_rating'] = train['road_rating'].astype('object')\n",
    "# test['road_rating'] = test['road_rating'].astype('object')\n",
    "\n",
    "# train['multi_linked'] = train['multi_linked'].astype('object')\n",
    "# test['multi_linked'] = test['multi_linked'].astype('object')\n",
    "\n",
    "# train['connect_code'] = train['connect_code'].astype('object')\n",
    "# test['connect_code'] = test['connect_code'].astype('object')\n",
    "\n",
    "# train['road_type'] = train['road_type'].astype('object')\n",
    "# test['road_type'] = test['road_type'].astype('object')\n",
    "\n",
    "# train['turn_restricted'] = train['turn_restricted'].astype('object')\n",
    "# test['turn_restricted'] = test['turn_restricted'].astype('object')\n",
    "\n",
    "print(\"Factor Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking\n",
    "\n",
    "data = train.iloc[:,:-1]\n",
    "label = train['target']\n",
    "\n",
    "train_data, val_data, train_label, val_label = train_test_split(data, label, test_size=0.16, random_state=42)\n",
    "\n",
    "# # declare model\n",
    "xgb = XGBRegressor(learning_rate=0.1)\n",
    "lgb = LGBMRegressor()\n",
    "cb = CatBoostRegressor(learning_rate=0.04557838437986454,\n",
    "        bagging_temperature=8.869692984509859,\n",
    "        n_estimators=6627,\n",
    "        max_depth=13,\n",
    "        random_strength=38,\n",
    "        colsample_bylevel=0.7379492985439079,\n",
    "        l2_leaf_reg=1.980433349323205e-05,\n",
    "        min_child_samples=14,\n",
    "        max_bin=337,\n",
    "        od_type='Iter',\n",
    "        one_hot_max_size=24,\n",
    "        loss_function='MAE')\n",
    "\n",
    "# Stacking model\n",
    "estimators = [('xgb',xgb), ('lgb',lgb), ('cb',cb)]\n",
    "stackingmodel = StackingRegressor(estimators=estimators, final_estimator=cb, n_jobs=-1, passthrough=True, verbose=300)\n",
    "stackingmodel.fit(train_data, train_label)\n",
    "\n",
    "stack_pred = stackingmodel.predict(val_data)\n",
    "score = mae(stack_pred, val_label)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inference\n",
    "\n",
    "sub = pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "sub['target'] = stackingmodel.predict(test)\n",
    "sub.to_csv('./result/submit26.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Train\n",
    "\n",
    "data = train.iloc[:,:-1]\n",
    "label = train['target']\n",
    "\n",
    "train_data, val_data, train_label, val_label = train_test_split(data, label, test_size=0.16)\n",
    "\n",
    "model = CatBoostRegressor(\n",
    "        learning_rate=0.035,\n",
    "        n_estimators=10000,\n",
    "        loss_function='MAE'\n",
    ").fit(X=train_data, y=train_label, \n",
    "    eval_set=(val_data, val_label), verbose=1000,\n",
    "    early_stopping_rounds=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inference\n",
    "\n",
    "sub = pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "sub['target'] = stackingmodel.predict(test)\n",
    "sub.to_csv('./result/submit24.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('cnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d43b4f546223569313ccfff62c0ebc3ac52433fbaef4ef84674b2a98664dd48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
